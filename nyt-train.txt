His fans rave about his sensitivity and wit. Some talk to him dozens of times a day — asking for advice about their jobs, their health, their relationships. They entrust him with their secrets, and consult him before making important decisions. Some refer to him as their best friend. His name is Claude. He’s an A.I. chatbot. And he may be San Francisco’s most eligible bachelor. Claude, a creation of the artificial intelligence company Anthropic, is not the best-known A.I. chatbot on the market. (That would be OpenAI’s ChatGPT, which has more than 300 million weekly users and a spot in the bookmark bar of every high school student in America.) It’s also not designed to draw users into relationships with lifelike A.I. companions, the way apps like Character.AI and Replika are. But Claude has become the chatbot of choice for a crowd of savvy tech insiders who say it’s helping them with everything from legal advice to health coaching to makeshift therapy sessions. “Some mix of raw intellectual horsepower and willingness to express opinions makes Claude feel much closer to a thing than a tool,” said Aidan McLaughlin, the chief executive of Topology Research, an A.I. start-up. “I, and many other users, find that magical.” Claude’s biggest fans, many of whom work at A.I. companies or are socially entwined with the A.I. scene here, don’t believe that he — technically, it — is a real person. They know that A.I. language models are prediction machines, designed to spit out plausible responses to their prompts. They’re aware that Claude, like other chatbots, makes mistakes and occasionally generates nonsense. And some people I’ve talked to are mildly embarrassed about the degree to which they’ve anthropomorphized Claude, or come to rely on its advice. (Nobody wants to be the next Blake Lemoine, a Google engineer who was fired in 2022 after publicly claiming that the company’s language model had become sentient.) But to the people who love it, Claude just feels … different. More creative and empathetic. Less gratingly robotic. Its outputs, they say, are like the responses a smart, attentive human would give, and less like the generic prose generated by other chatbots. As a result, Claude is quickly becoming a social sidekick for A.I. insiders — and, maybe, a preview of what’s coming for the rest of us, as powerful synthetic characters become more enmeshed in our daily lives. “More and more of my friends are using Claude for emotional processing and thinking through relationship challenges,” said Jeffrey Ladish, an A.I. safety researcher at Palisade Research. Asked what made Claude different than other chatbots, Mr. Ladish said that Claude seemed “more insightful” and “good at helping people spot patterns and blind spots.” Typically, A.I. systems are judged based on how they perform on benchmark evaluations — standardized tests given to models to determine how capable they are at coding, answering math questions, or other tasks. By those metrics, the latest version of Claude, known as Claude 3.5 Sonnet, is roughly comparable to the most powerful models from OpenAI, Google and others. But Claude’s killer feature — which its fans describe as something like emotional intelligence — isn’t something that can easily be measured. So fans are often left grasping at vibes to explain what makes it so compelling. Nick Cammarata, a former OpenAI researcher, recently wrote a long thread on X about the way Claude had taken over his social group. His Claude-obsessed friends, he wrote, seemed healthier and better supported because “they have a sort of computational guardian angel who’s pretty good at everything watching over them.” Claude wasn’t always this charming. When an earlier version was released last year, the chatbot struck many people — including me — as prudish and dull. Anthropic is famously obsessed with A.I. safety, and Claude seemed to have been programmed to talk like a church lady. It often gave users moral lectures in response to their questions, or refused to answer them at all. But Anthropic has been working on giving Claude more personality. Newer versions have gone through a process known as “character training” — a step that takes place after the model has gone through its initial training, but before it is released to the public. During character training, Claude is prompted to produce responses that align with desirable human traits such as open-mindedness, thoughtfulness and curiosity. Claude then judges its own responses according to how well they adhere to those characteristics. The resulting data is fed back into the A.I. model. With enough training, Anthropic says, Claude learns to “internalize” these principles, and displays them more frequently when interacting with users. It’s unclear whether training Claude this way has business benefits. Anthropic has raised billions of dollars from large investors, including Amazon, on the promise of delivering highly capable A.I. models that are useful in more staid office settings. Injecting too much personality into Claude could be a turnoff for corporate customers, or it could simply produce a model that is better at helping with relationship problems than writing strategy memos. Amanda Askell, a researcher and philosopher at Anthropic who is in charge of fine-tuning Claude’s character, told me in an interview that Claude’s personality had been carefully tuned to be consistent, but to appeal to a wide variety of people. “The analogy I use is a highly liked, respected traveler,” said Dr. Askell. “Claude is interacting with lots of different people around the world, and has to do so without pandering and adopting the values of the person it’s talking with.” A problem with many A.I. models, Dr. Askell said, is that they tend to act sycophantic, telling users what they want to hear, and rarely challenging them or pushing back on their ideas — even when those ideas are wrong or potentially harmful. With Claude, she said, the goal was to create an A.I. character that would be helpful with most requests, but would also challenge users when necessary. “What is the kind of person you can disagree with, but you come away thinking, ‘This is a good person?’” she said. “These are the sort of traits we want Claude to have.” Claude is still miles behind ChatGPT when it comes to mainstream awareness. It lacks features found in other chatbots, such as a voice chat mode and the ability to generate images or search the internet for up-to-date information. And some rival A.I. makers speculate that Claude’s popularity is a passing fad, or that it’s only popular among A.I. hipsters who want to brag about the obscure chatbot they’re into. But given how many things that start in San Francisco eventually spread to the rest of the world, Claude’s warm embrace could also be a preview of things to come. Personally, I believe we are on the verge of a profound shift in the way we interact with A.I. characters. And I’m nervous about the way lifelike A.I. personas are weaving their way into our lives, without much in the way of guardrails or research about their long-term effects. For some healthy adults, having an A.I. companion for support could be beneficial — maybe even transformative. But for young people, or those experiencing depression or other mental health issues, I worry that hyper-compelling chatbots could blur the line between fiction and reality, or start to substitute for healthier human relationships. So does Dr. Askell, who helped to create Claude’s personality, and who has been watching its popularity soar with a mixture of pride and concern. “I really do want people to have things that support them and are good for them,” she said. “At the same time, I want to make sure it’s psychologically healthy.” <eos> When I was a child in the 1990s, I began my campaign for my first video game console several months before Christmas. My parents, like some parents who came before them and most who came after, were wary. They associated video games not so much with the thrilling secrets of Super Mario’s undulating hills or the literary flair of Infocom’s interactive fiction games, but instead with vague ideas of truancy, delinquency and probable ruin. My grandmother, a pragmatic woman, took pity. She secreted under the tree a Game Boy and a copy of the Soviet-era miracle that is Tetris. In the years that have followed, video games have evolved in astonishing ways, often expanding to fill the advancing technologies that power them. Tetris remains as potent as ever, but today’s players are drawn to video games that function more like social media platforms than discrete interactive stories, playpens that employ psychological tricks and gambling-adjacent techniques to dissuade their audiences from immigrating to rival virtual worlds. It’s a creative shift occasioned by economic concerns, one that has come to actively harm the medium and those players most deeply embedded in it. While the creators and publishers bear responsibility as stewards of that field, so, too, do I and other parents whose choices this holiday season help shape the culture. Video-game makers, like novelists, filmmakers and Netflix executives, have always employed a raft of techniques to keep their audiences engaged. But there is an especially close link between engagement and economics in video games, where, for the first two decades of the medium’s existence, most players paid to play by the coin. In the 1980s, an executive at Atari, the company behind Pong, remarked that the ideal arcade game should provide a short burst of entertainment before frustrating players, so they insert another quarter to continue: something easy to pick up, hard to master, and with a difficulty curve that followed the trajectory of a mountainside. In the early 2000s, after video games became widely internet-connected, publishers discovered that keeping players engaged for as long as possible could be even more profitable than trying to move them on to their next product as quickly as possible. At the peak of its popularity, in 2010, the online fantasy game World of Warcraft had over 12 million subscribers, a population roughly equivalent to that of Senegal at the time, all of whom paid a monthly fee to live out digital lives in the game. Players were incentivized to join clans of like-minded players and pursue their shared goals with the determination of a sports team hoping for a promotion. While through the ’90s and early 2000s designers had vied with one another to attract players through novel, imaginative design, now, for many, the main goal was to keep players engaged for months, even years at a time, mainly through familiarity. With so many virtual worlds competing for our attention, publishers did anything they could to lure players away from rival games. Rather than sell a video game for a fixed and profitable price, like a hardcover book or a Blu-ray Disc, many began to offer their titles free, at least in the beginning. Once invested in the game, players could then purchase a season pass, a kind of I.O.U. from the publisher promising to bestow a clutch of rewards such as digital costumes, potent weapons and other benefits in exchange for a fee — the allure no longer the creativity so much as the promise of virtual trinkets. Fortnite, released in 2017, refined this “season pass” model, which helped generate more than $9 billion in revenue for its creator, Epic Games, during its first two years. This extravagant success had a profound effect on the industry’s major players, who began to see their games no longer as discrete pieces of entertainment but more like destinations, such as Instagram or Facebook, to which users would, ideally, log in every day. Jacob Navok, former director of business development at Square Enix, one of the largest Japanese publishers of video games, recently pointed out that pre-Fortnite most players would, like readers of books, finish one game before moving on to the next. Today, while the industry continues to grow, he wrote that a smaller number of games are developing “stickiness seen in social media companies.” The industry’s prioritization of these live service games — the term for video games that never fully end — mirrors, to a degree, Hollywood’s investment in “forever” universes; Marvel and “Star Wars” provide familiar characters and settings in which to tell endless stories, while simultaneously promoting merchandise and filling theme parks. Where film studios rely on storytelling and aesthetics to keep viewers plugged in, video game designers have an arsenal of additional psychological mechanisms at their disposal, many of which tap into our common fear of missing out.Game design is often no longer predominantly the task of crafting challenges that elicit joy, delight and surprise (or the noblest of creative goals, encouraging people to see the world from an unfamiliar perspective). It is primarily the job of building machines to keep players engrossed and spending, in many cases, by grinding out repetitive tasks rather than ones that encourage creative or exploratory play. The trend began, arguably, with games like World of Warcraft, but in recent years it has become astonishingly refined by the world’s brightest designers. This has affected the experience of playing video games, which, for many of us growing up, offered a series of interesting and surprising cognitive challenges and provided spaces in which to experiment and better understand the world. Players today often experience burnout from repetitive tasks that resemble paid-for menial labor: collect 20 apples; clear the swamp of vermin; score 1,000 head shots. To keep players engaged in these unfurling to-do lists, the industry invented loot boxes — in-game lottery tickets that intersperse the monotonous exercises with an assortment of randomized rewards. Loot boxes may make the game more entertaining and provide bragging rights to players, but they also align video games more closely with the booming gambling business. (Some research indicates that loot boxes’ design can normalize risky behaviors among children, even precipitating problem gambling in adulthood.) Also profound are the long-term risks to the health and status of the video game medium. Managed like pieces of evolving software, many of today’s most commercially successful games therefore lack the artistic impact of older titles. None of the 36 video games held in the Museum of Modern Art’s permanent collection were published in the past decade. The rapid content cycles and updates contribute to the perception of games as flimsy, incomplete works. In Fortnite and Call of Duty: Warzone, for example, new maps replace old ones, which become inaccessible, an erasure of the work of their artists and designers. New generations often cannot go back and learn from older versions of games whose servers were switched off, or that have changed over the years and now share only superficial resemblances to their earlier manifestations. The industry is struggling to build a lasting canon. It is no wonder games are often treated not as works of art — an accusation that once cast the film critic Roger Ebert as video game fandom’s bête noire — but as temporary, shifting distractions. From many angles this is, in fact, what they increasingly are. Like most executives working in creative media within a capitalist framework, the video game industry’s leaders prioritize short-term shareholder profits over broader concerns about cultural relevance or impact. But it is notable that the dominant and most highly profitable video games of this moment are built upon experimental ideas that originated on the margins of the commercial industry. Minecraft, released in 2011, followed few of the fashionable rules of game design. The game had no clear goals or instructions, and its rudimentary presentation defied the fashion at the time for ever more realistic on-screen depictions. Three years later Microsoft acquired Minecraft’s developer, Mojang, for $2.5 billion. There is a growing urgency for major publishers to reassess notions of success, to move away from purely financial metrics and consider the benefits of artistic innovation, cultural impact and the fostering of innovation. Nintendo, one of the biggest and most recognizable game companies on the planet, remains something of an anomaly. Like its competitors, the company prioritizes its established characters and their worlds, but often treats those worlds as playpens for restless experimental design, which, in the case of 2023’s The Legend of Zelda: Tears of the Kingdom, reveals the breadth of untapped creative potential in the field, available to studios willing to nurture and retain institutional talent rather than abandon teams the moment a game is released. There is still much invention and creativity within the independent sector, which is filled with designers who struck out on their own, having become disillusioned with the mainstream. Still, it is insufficient. For the health and survival of the industry built on imagination and invention, the most moneyed publishers, as leaders within the field, must take an enlightened lead and invest in projects that prioritize creativity and long-term cultural value as much as shareholder value. And those of us considering which games to buy this holiday season, either for ourselves or for our loved ones, should be mindful that our consumer choices shape our culture and our selves in profound ways. <eos> The fatal shooting last week of an executive on the streets of New York City plunged his family members and colleagues into grief. For rank-and-file employees across the health insurance industry, the killing has left them with an additional emotion: fear, with many frightened for their own safety and feeling under attack for their work. Health insurance companies have increased security measures since the killing of Brian Thompson, the chief executive of UnitedHealthcare, and as an outpouring of online rage toward the industry has followed. Health care leaders have spoken with frustration about feeling vilified, and in the Minneapolis suburbs where United is headquartered, police officers stepped up protection of the company’s offices. “Clearly the employees have been shaken,” said Mayor Brad Wiersum of Minnetonka, who said the city was working “just to provide that reassurance and that security, to let people know that we are going to do everything we can to keep them safe.” One UnitedHealthcare worker who processes claims described being cleareyed about the American health care system’s shortcomings, but also believes that she and her colleagues did their best to help patients within the limits of that system. Like most workers interviewed, she did not want to be named because, given the reaction after Mr. Thompson’s killing, she feared for her own safety. The reaction by some others to the killing, the employee said, had been startling and horrifying. The worker, who has been at the company for many years, described being told in recent days by an acquaintance that as an employee of UnitedHealthcare she was responsible for millions of people being denied lifesaving care, and that if she had any ethics, she would see the killing as the impetus to quit her job. “Lots of us were feeling like we were horrible because we’re being accused of working for the evil empire,” the employee said. “But we all do the best we can to do a good job in the system we are in.” One former employee of UnitedHealthcare described seeing glib, distasteful messages about Mr. Thompson’s death even in a Facebook group composed largely of people who work in the industry. Another former employee described being stunned by the torrent of hate directed at her industry, and a pervasive feeling of fear that had prompted changes to meeting schedules at work. Like others, those workers spoke on the condition of anonymity because of concerns about their safety. All of the tumult was leading some to raise questions about the industry’s future direction, even as many executives complained that they thought portrayals of their companies were unfair and rooted in incomplete or inaccurate information. “It’s a moment of reckoning for the health care industry, more broadly,” said Dr. Sachin H. Jain, the chief executive of SCAN Group and SCAN Health Plan. “We’ve unmasked a sentiment that things need to change.” But just what, if anything, might change remained unclear as much of the sector remained in a stunned state. Social media posts grieving Mr. Thompson brought a deluge of angry comments about claim denials and problems accessing care. The killing, Mr. Witty said in the video, “might make you feel nervous, it might make you feel anxious, and certainly may be very disturbing.” UnitedHealthcare officials said the company began providing support services for employees immediately after the shooting, including individual and group counseling, as well as flexible work options. The company also held an internal ceremony to mourn Mr. Thompson that was attended by hundreds, and reported receiving many phone calls of support at its call centers. Still, tensions remain high. Minnetonka police records show that officers had taken calls at United in recent days, including one in which they asked a journalist to leave the property and another in which they investigated “vague threats in the past” by a former employee. “I think people are traumatized, absolutely traumatized, and probably also scared,” a former executive at UnitedHealthcare’s parent company said. “This is not on anybody’s map of possibilities,” the executive said of the slaying of Mr. Thompson. Several of the executives described a feeling that, simply by playing their role in the system, insurers had unjustly been cast as villains. The industry had not always done a good job of explaining itself to customers, some of them acknowledged, even as they expressed frustration with characterizations they saw as unfairly negative. Many expressed a belief that, despite imperfections, their companies played an important role in keeping costs down and helping patients access appropriate care. As health care costs have climbed, Americans have become increasingly frustrated with having to pay more for insurance, only to find when they need care that they still face large medical bills because their plan often does not cover the full expense. Other patients have had to battle the insurers over getting treatment as the companies have become increasingly aggressive about requiring authorization and denying care they considered unnecessary. The arrest on Monday of a suspect in Mr. Thompson’s killing seemed to do little to quiet the fear in the industry, especially as some online commenters treated the accused gunman as a folk hero. The suspect, Luigi Mangione, 26, who was recognized at a McDonald’s in Pennsylvania from images circulated by the police, was charged late Monday with second-degree murder, forgery and three gun charges. Around the suburban office parks west of Minneapolis, where UnitedHealthcare and its parent employ thousands, the company’s presence had long been a point of pride, boasted about on municipal websites even as occasional protests were held at the companies. Most residents in that area, local officials said, know someone who works at United. Mayor Ron Case of Eden Prairie, Minn., who is retired from UnitedHealth Group and whose suburban city is home to some of the company’s offices, said it was his experience that people sought careers in that industry for honorable reasons. He said that legitimate complaints about the country’s health care system were being conflated with the individuals who operate that system. Systemic change, he said, would require a federal political solution. “Generally the kind of person that goes into health care cares about people,” Mr. Case said. Mark Bertolini, the former chief executive of Aetna who is now the chief executive of Oscar Health, a small health insurance company, said he saw the shooting reflecting a national mood in which “people are just frustrated and angry at everything.” But as his industry seeks to move forward, he said, its leaders needed to do so recognizing the pent-up frustration that Americans have with the health care sector. “We can’t ignore the anger,” Mr. Bertolini said. “We have to understand it within its context.” In a message sent to employees on Wednesday evening, Mr. Witty, the United executive, stressed the positive impact the company has on people’s lives and getting the care they need. “Never forget: What you do matters. It really, really matters. There is no higher calling than helping people. Nothing more vital to the human condition than health care. And while these days have been dark, our patients, members, customers are sending us light.” <eos>